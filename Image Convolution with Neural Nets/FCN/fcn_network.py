# -*- coding: utf-8 -*-
"""FCN_Network.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MXn5jRNyjv_NKO2hJ56zYnGQ0DAnXHYg

Install Required Libraries
"""

# Install necessary libraries
!pip install torch torchvision matplotlib Pillow

# Import required libraries
import torch
from torchvision import models, transforms
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
import os

"""Prepare Images"""

from google.colab import drive
drive.mount('/content/drive')

# Path to the folder containing the images
image_folder = '/content/drive/MyDrive/fcn_images'

# List the image files
image_files = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith(('.jpg', '.png'))]

# Define transformations for resizing, normalizing, and converting to tensor
data_transforms = transforms.Compose([
    transforms.Resize((256, 256)),  # Resize images
    transforms.ToTensor(),  # Convert to tensor
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize
])

"""Load Pre-trained FCN Network"""

# Load pretrained FCN model
model = models.segmentation.fcn_resnet50(pretrained=True)
model.eval()  # Set model to evaluation mode

# Move model to GPU if available
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
model = model.to(device)

"""Define Helper Functions"""

def save_feature_maps(output, save_folder, image_name):
    """
    Save the 21 feature maps as tiles in one image, in the same folder as the original images.
    """
    feature_maps = output['out'].squeeze(0).detach().cpu().numpy()  # Extract feature maps
    num_maps = feature_maps.shape[0]
    grid_size = int(np.ceil(np.sqrt(num_maps)))  # Determine grid size for tiles
    fig, axes = plt.subplots(grid_size, grid_size, figsize=(15, 15))

    for i, ax in enumerate(axes.flat):
        if i < num_maps:
            ax.imshow(feature_maps[i], cmap='viridis')
        ax.axis('off')
    plt.tight_layout()
    save_path = os.path.join(save_folder, f"{image_name}_feature_maps.png")
    plt.savefig(save_path)
    plt.close()

def create_segmentation(output, save_folder, image_name):
    """
    Create a segmentation image where each color represents one class,
    and save it in the same folder as the original images.
    """
    seg_map = torch.argmax(output['out'], dim=1).squeeze(0).cpu().numpy()  # Get class indices
    # Use a random color map for visualization
    colormap = np.random.randint(0, 255, (21, 3), dtype=np.uint8)  # 21 classes
    segmentation = colormap[seg_map]  # Map class indices to colors
    plt.imshow(segmentation)
    plt.axis('off')
    save_path = os.path.join(save_folder, f"{image_name}_segmentation.png")
    plt.savefig(save_path)
    plt.close()

"""Process each image"""

for image_file in image_files:
    # Load and preprocess the image
    img = Image.open(image_file).convert('RGB')
    input_tensor = data_transforms(img).unsqueeze(0).to(device)

    # Get the network output
    with torch.no_grad():
        output = model(input_tensor)

    # Save feature maps and segmentation in the same folder as the original images
    image_name = os.path.splitext(os.path.basename(image_file))[0]
    save_folder = os.path.dirname(image_file)  # Get the folder path of the original image
    save_feature_maps(output, save_folder, image_name)
    create_segmentation(output, save_folder, image_name)

    print(f"Processed and saved results for {image_file}")