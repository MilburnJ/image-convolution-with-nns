# -*- coding: utf-8 -*-
"""VGG16 _CIFAR100.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17MJJ5-wcfJaIZrqURbHGzk8zrZAoXztn

Install and import libraries
"""

# Install necessary libraries
!pip install torch torchvision

# Import required libraries
import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
import numpy as np
import torchvision
from torchvision import datasets, models, transforms

"""Define Data Transformations"""

# Define transformations for resizing, normalizing, and augmenting the dataset
data_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
])

"""Load CIFAR100 Dataset"""

# Define dataset root directory
dataset_root = './data'

# Load CIFAR100 dataset
trainset = datasets.CIFAR100(root=dataset_root, train=True, transform=data_transforms, download=True)
testset = datasets.CIFAR100(root=dataset_root, train=False, transform=data_transforms, download=True)

"""Create Data Loaders"""

# Define data loaders
trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)
testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)

"""Load Pretrained VGG16 Model"""

# Load pretrained VGG16 model
model = models.vgg16(pretrained=True)

# Modify the last fully connected layer for CIFAR100
num_in_ftrs = model.classifier[6].in_features
num_cls = 100  # CIFAR100 has 100 classes
model.classifier[6] = nn.Linear(num_in_ftrs, num_cls)

# Freeze all layers except the last layer
for param in model.parameters():
    param.requires_grad = False
for param in model.classifier[6].parameters():
    param.requires_grad = True

"""Set Device and Hyperparams"""

# Move model to GPU if available
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
model = model.to(device)

# Define loss function, optimizer, and learning rate scheduler
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.classifier[6].parameters(), lr=0.001, momentum=0.9)
scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)

# Set the number of epochs
num_epochs = 10

"""Train model"""

# Training loop
best_acc = 0.0
best_model_wts = model.state_dict()

for epoch in range(num_epochs):
    print(f'Epoch {epoch + 1}/{num_epochs}')
    print('-' * 10)

    model.train()
    running_loss = 0.0
    running_corrects = 0

    for images, labels in trainloader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        _, preds = torch.max(outputs, 1)
        running_loss += loss.item() * images.size(0)
        running_corrects += torch.sum(preds == labels.data)

    scheduler.step()

    epoch_loss = running_loss / len(trainset)
    epoch_acc = running_corrects.double() / len(trainset)
    print(f'Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')

    if epoch_acc > best_acc:
        best_acc = epoch_acc
        best_model_wts = model.state_dict()

torch.save(best_model_wts, 'best_model_VGG.pth')

"""Test Model"""

# Load the best model weights
model.load_state_dict(torch.load('best_model_VGG.pth'))
model.eval()

running_corrects = 0

for images, labels in testloader:
    images, labels = images.to(device), labels.to(device)

    outputs = model(images)
    _, preds = torch.max(outputs, 1)
    running_corrects += torch.sum(preds == labels.data)

test_acc = running_corrects.double() / len(testset)
print(f'Test Accuracy: {test_acc:.4f}')