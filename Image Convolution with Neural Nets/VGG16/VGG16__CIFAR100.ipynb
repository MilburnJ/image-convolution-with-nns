{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install and import libraries"
      ],
      "metadata": {
        "id": "lxYzMyaBIs3Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5Kn4QlSIRzW",
        "outputId": "5edb74e3-f5b0-4b38-e345-b558caae90c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install torch torchvision\n",
        "\n",
        "# Import required libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Data Transformations"
      ],
      "metadata": {
        "id": "cIWRfZlOIv8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations for resizing, normalizing, and augmenting the dataset\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n"
      ],
      "metadata": {
        "id": "FGRrIn-oIx-d"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load CIFAR100 Dataset"
      ],
      "metadata": {
        "id": "F9z5beaoI3E4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset root directory\n",
        "dataset_root = './data'\n",
        "\n",
        "# Load CIFAR100 dataset\n",
        "trainset = datasets.CIFAR100(root=dataset_root, train=True, transform=data_transforms, download=True)\n",
        "testset = datasets.CIFAR100(root=dataset_root, train=False, transform=data_transforms, download=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSogw3E0Izf2",
        "outputId": "3b0dd696-4e79-429c-aa9f-2efc9a93d44f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169M/169M [00:01<00:00, 104MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Data Loaders"
      ],
      "metadata": {
        "id": "okXBy6YdI9Tq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data loaders\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "nawEBGKOJRWr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Pretrained VGG16 Model"
      ],
      "metadata": {
        "id": "8N9xkXvIJSME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pretrained VGG16 model\n",
        "model = models.vgg16(pretrained=True)\n",
        "\n",
        "# Modify the last fully connected layer for CIFAR100\n",
        "num_in_ftrs = model.classifier[6].in_features\n",
        "num_cls = 100  # CIFAR100 has 100 classes\n",
        "model.classifier[6] = nn.Linear(num_in_ftrs, num_cls)\n",
        "\n",
        "# Freeze all layers except the last layer\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "for param in model.classifier[6].parameters():\n",
        "    param.requires_grad = True\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m894JDInJSn_",
        "outputId": "287db8cf-4980-4c90-d7dc-159e6b26635d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:02<00:00, 221MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set Device and Hyperparams"
      ],
      "metadata": {
        "id": "sESgErXRJZgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Move model to GPU if available\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "# Define loss function, optimizer, and learning rate scheduler\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.classifier[6].parameters(), lr=0.001, momentum=0.9)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "# Set the number of epochs\n",
        "num_epochs = 10\n"
      ],
      "metadata": {
        "id": "qf8qjJWGJZNE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train model"
      ],
      "metadata": {
        "id": "Qnm7XtstJdPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "best_acc = 0.0\n",
        "best_model_wts = model.state_dict()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}')\n",
        "    print('-' * 10)\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "\n",
        "    for images, labels in trainloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    epoch_loss = running_loss / len(trainset)\n",
        "    epoch_acc = running_corrects.double() / len(trainset)\n",
        "    print(f'Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "    if epoch_acc > best_acc:\n",
        "        best_acc = epoch_acc\n",
        "        best_model_wts = model.state_dict()\n",
        "\n",
        "torch.save(best_model_wts, 'best_model_VGG.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpfOc6OnJeWX",
        "outputId": "9281d9ef-ddb1-4625-e0bf-3b63fe231862"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "----------\n",
            "Loss: 2.7018 Acc: 0.3811\n",
            "Epoch 2/10\n",
            "----------\n",
            "Loss: 1.8611 Acc: 0.5123\n",
            "Epoch 3/10\n",
            "----------\n",
            "Loss: 1.7028 Acc: 0.5384\n",
            "Epoch 4/10\n",
            "----------\n",
            "Loss: 1.6192 Acc: 0.5537\n",
            "Epoch 5/10\n",
            "----------\n",
            "Loss: 1.5587 Acc: 0.5672\n",
            "Epoch 6/10\n",
            "----------\n",
            "Loss: 1.5266 Acc: 0.5723\n",
            "Epoch 7/10\n",
            "----------\n",
            "Loss: 1.4971 Acc: 0.5808\n",
            "Epoch 8/10\n",
            "----------\n",
            "Loss: 1.4541 Acc: 0.5895\n",
            "Epoch 9/10\n",
            "----------\n",
            "Loss: 1.4522 Acc: 0.5945\n",
            "Epoch 10/10\n",
            "----------\n",
            "Loss: 1.4460 Acc: 0.5938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Model"
      ],
      "metadata": {
        "id": "s23dmQY2JiPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model weights\n",
        "model.load_state_dict(torch.load('best_model_VGG.pth'))\n",
        "model.eval()\n",
        "\n",
        "running_corrects = 0\n",
        "\n",
        "for images, labels in testloader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "test_acc = running_corrects.double() / len(testset)\n",
        "print(f'Test Accuracy: {test_acc:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eOWD9jIJhuX",
        "outputId": "c3283dde-c42f-438f-8042-36a8a1f92b53"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-4420f1249727>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('best_model_VGG.pth'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.6138\n"
          ]
        }
      ]
    }
  ]
}